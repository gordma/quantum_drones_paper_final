\section{Results}
\label{sec:results}

% --- New subsection: Route-generation parameter sweep ------------------
\subsection{Route-Generation Parameter Exploration}

To select a \emph{softness} parameter $S$ that balances raw performance with
reproducibility, we conducted a comprehensive grid search covering
$14$~softness values ($0.5$--$30.0$) with $30$ random seeds each
(Fig.~\ref{fig:softness_pareto}).  For each~$S$ we report the mean best cost
and its coefficient of variation (CV~=~$\sigma/\mu$).  The lower--left
corner of the plot therefore represents the Pareto--optimal region where
solutions are both \	extit{good} and \	extit{consistent}.

\begin{figure}[htb]
    \centering
    % TODO: include softness Pareto figure
    \includegraphics[width=0.7\linewidth]{figures/00_softness_pareto.png}
    \caption{Pareto frontier of GA performance (mean best cost) versus consistency
    (CV) across the route‐generation softness sweep ($n_{\text{routes}}=2048$,
    $30$ seeds each).  Although $S=0.7$ attains the best mean cost, the
    research choice $S=6.0$ lies on the Pareto frontier, achieving a 26\%
    lower variance for only a 0.3\% performance penalty, thus providing a more
    reproducible and diverse benchmark for downstream quantum experiments.}
    \label{fig:softness_pareto}
\end{figure}

Based on this analysis we adopt $S=6.0$ for all subsequent experiments,
trading a negligible performance loss for markedly improved consistency and
route diversity.

\subsection{Classical Performance Ceiling Establishment}

Before evaluating quantum performance, we establish the performance ceiling of classical optimization to ensure fair quantum comparison.

% FIGURE PLACEMENT: Figure 1 - GA Performance Ceiling
% WHY HERE: Establishes classical performance ceiling for quantum comparison
% Demonstrates robust high-mutation band used in subsequent comparisons
% DATA SOURCE: ga_equal_budget_results.csv from experiments/ga_analysis/run_ga_equal_budget.py

\begin{figure}[htb]
    \centering
    % TODO: Insert ga_mutation_sweep.png with robust band emphasis
    \caption{Classical optimization baseline establishment. Mutation probabilities $\mu \in [0.20, 0.25]$ (blue shaded band) yield the lowest \emph{average} cost and smallest variance, confirming that moderately high mutation rates represent the robust sweet-spot. Lower $\mu$ risks premature convergence, while excessively high $\mu > 0.25$ never outperforms the shaded region. The classical performance ceiling of 7\,790 establishes the benchmark quantum methods must surpass.}
    \label{fig:ga_mutation}
\end{figure}

Systematic analysis across mutation rates $\mu \in \{0.15, 0.18, 0.20, 0.22, 0.25\}$ reveals the robust high-mutation band:
\begin{itemize}[nosep]
    \item \textbf{Performance ceiling}: 7\,790 cost (absolute minimum across all trials)
    \item \textbf{Robust band}: $\mu \in [0.20, 0.25]$ consistently yields low-cost, low-variance solutions  
    \item \textbf{Degradation zones}: $\mu < 0.18$ (premature convergence) and $\mu > 0.25$ (excessive randomization)
\end{itemize}

This establishes a rigorously optimized classical performance ceiling of 7\,790 against which quantum methods must demonstrate superiority.

\subsection{Main Result: Quantum Advantage Across Optimizers}

We now present the core experimental finding: CVaR-VQE consistently outperforms the optimized GA across multiple Bayesian optimization strategies.

% TABLE PLACEMENT: Table 1 - Main Comparison Results  
% WHY HERE: Central claim of paper - the 6-8% quantum advantage
% Directly supports intro.tex headline claim
% DATA SOURCE: experiments/vqe_final/ (30 trials each) + ga_equal_budget_results.csv

\begin{table}[htb]
    \centering
    \caption{Performance comparison between GA baseline and CVaR-VQE variants under identical 400\,000-evaluation budget. All VQE configurations achieve 5--7\% improvement over the mutation-optimized GA, demonstrating robust quantum advantage across optimization strategies.}
    \label{tab:main_results}
    \begin{tabular}{lcccr}
        \toprule
        Method & Best Cost & Mean $\pm$ Std & $n$ & vs GA \\
        \midrule
        GA ($\mu^* = 0.22$) & 7\,790 & $8\,493 \pm 420$ & 30 & -- \\
        VQE Aggressive-TPE & \textbf{7\,290} & $7\,905 \pm 325$ & 30 & \textbf{-6.9\%} \\
        VQE Default-TPE & 7\,330 & $7\,985 \pm 250$ & 30 & \textbf{-6.0\%} \\
        VQE Random & 7\,330 & $8\,058 \pm 300$ & 30 & \textbf{-5.1\%} \\
        \bottomrule
    \end{tabular}
\end{table}

The quantum advantage persists across optimization strategies:
\begin{itemize}[nosep]
    \item \textbf{Aggressive-TPE}: 6.9\% improvement (most pronounced)
    \item \textbf{Default-TPE}: 6.0\% improvement (robust to hyperparameters)  
    \item \textbf{Random sampling}: 5.1\% improvement (surprising baseline performance)
\end{itemize}

Notably, even naive random parameter sampling within the CVaR-VQE framework outperforms sophisticated classical optimization, suggesting the quantum representation itself provides fundamental advantages for this problem structure.

\subsection{Parameter Space Robustness}

To ensure the quantum advantage is not confined to a narrow hyperparameter regime, we systematically explore the CVaR-VQE parameter landscape.

% FIGURE PLACEMENT: Figure 2 - VQE Parameter Heatmap
% WHY HERE: After establishing main result, show it's robust across hyperparameters  
% Demonstrates NISQ-scale practicality claim from intro
% DATA SOURCE: experiments/vqe_plateau_grid/ with 30 trials per (α,L) combination

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/vqe_alpha_layer_heatmap.png}
    \caption{CVaR-VQE performance across risk parameter $\alpha$ and circuit depth $L$. Shallow circuits ($L \leq 2$) consistently outperform, with $\alpha \approx 0.05$ emerging as optimal across depths. Controls at $\alpha = 0.50$ (median-risk) and $\alpha = 1.00$ (mean-cost) confirm that focusing on the worst \emph{5--10\%} of outcomes yields the greatest improvement. An over-parameterised depth $L = 5$ slice further shows that adding variational layers beyond two offers no additional benefit and can slightly degrade performance. The broad low-cost region therefore demonstrates a \emph{robust}, \emph{shallow-circuit} quantum advantage independent of precise hyper-parameter tuning.}
    \label{fig:vqe_heatmap}
\end{figure>

Key observations:
\begin{itemize}[nosep]
    \item \textbf{Shallow circuit dominance}: $L \in \{1, 2\}$ layers consistently outperform deeper alternatives
    \item \textbf{Over-parameterisation control}: Increasing depth to $L = 5$ \emph{does not} improve---and occasionally worsens---performance, indicating two layers already saturate expressive capacity for this problem.
    \item \textbf{Risk parameter sweep}: Extreme settings ($\alpha = 1.00$ mean-cost and $\alpha = 0.50$ median-risk) close most of the quantum gap, while $\alpha \approx 0.05$ (top 5\% tail) remains optimal.
    \item \textbf{Robust advantage region}: Dozens of $(\alpha, L)$ combinations achieve $<8\,000$ cost, well below GA baseline, indicating low hyper-parameter sensitivity.
\end{itemize}

This parameter robustness validates practical deployability: the quantum advantage does not require precise hyperparameter tuning.

\subsection{Budget Scaling Analysis}

Having established quantum advantage under standard budgets, we investigate performance across different computational resource allocations.

% TABLE PLACEMENT: Table 2 - Budget Scaling Results
% WHY HERE: After main result + robustness, show scaling behavior
% Validates both extended budget claims and plateau efficiency from intro
% DATA SOURCE: experiments/vqe_extended_budget_1000/ + experiments/vqe_plateau_70/

\begin{table}[htb]
    \centering
    \caption{Performance scaling across evaluation budgets. VQE maintains competitive performance even under reduced budgets, while extended budgets yield diminishing returns for both methods.}
    \label{tab:budget_scaling}
    \begin{tabular}{lcccc}
        \toprule
        Method & Budget & Best & Mean $\pm$ Std & Efficiency \\
        \midrule
        VQE (70 iter) & 120\,k evals & 7\,840 & $8\,142 \pm 238$ & High \\
        VQE (200 iter) & 400\,k evals & 7\,290 & $7\,905 \pm 325$ & Medium \\
        VQE (1000 iter) & 2\,M evals & 7\,300 & $7\,334 \pm 22$ & Low \\
        GA (tuned) & 2\,M evals & 7\,790 & $8\,493 \pm 420$ & Low \\
        \bottomrule
    \end{tabular}
\end{table}

Budget scaling reveals:
\begin{itemize}[nosep]
    \item \textbf{Practical efficiency}: 70-iteration VQE (120\,k evaluations) remains competitive with full GA
    \item \textbf{Diminishing returns}: Beyond 400\,k evaluations, both methods show plateau behavior
    \item \textbf{Quantum consistency}: VQE variance decreases with budget, suggesting stable convergence
\end{itemize}

\subsection{Convergence Dynamics}

To understand the optimization mechanisms underlying quantum advantage, we analyze learning curves and convergence patterns.

% FIGURE PLACEMENT: Figure 3 - Learning Curves Comparison
% WHY HERE: After performance + scaling, show HOW the advantage emerges
% Technical validation supporting the quantum advantage claim
% DATA SOURCE: experiments/vqe_final/aggressive_tpe/ + experiments/ga_analysis/ga_trajectory_cache.pkl

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/02_ga_vs_vqe_learning_curve.png}
    \caption{Convergence comparison between CVaR-VQE (Aggressive-TPE) and mutation-optimized GA. VQE demonstrates faster initial convergence and achieves lower asymptotic cost. The plateau at $\approx 70$ iterations validates our reduced-budget experimental design.}
    \label{fig:learning_curves}
\end{figure>

Convergence analysis reveals:
\begin{itemize}[nosep]
    \item \textbf{Faster convergence}: VQE reaches near-optimal solutions in $\sim 70$ iterations vs $>200$ for GA
    \item \textbf{Superior asymptote}: VQE converges to lower cost than GA plateau
    \item \textbf{Plateau validation}: Both methods show diminishing improvement beyond 70--100 iterations
\end{itemize}

\subsection{Noise Robustness: Realistic Deployment Validation}

To assess practical quantum deployment viability, we evaluate CVaR-VQE performance under calibrated hardware noise.

% TABLE PLACEMENT: Table 3 - Noise Robustness Results
% WHY HERE: After convergence analysis, validate real-world viability 
% Directly supports intro.tex claim about ibm_fez noise model
% DATA SOURCE: experiments/vqe_noise_L1_a0.05/, experiments/vqe_noise_L2_a0.05/, experiments/vqe_noise_L2_a1.0/

\begin{table}[htb]
    \centering
    \caption{Performance under IBM \texttt{ibm\_fez} noise model. Shallow circuits ($L=1$) show remarkable noise resilience, while $L=2$ circuits exhibit modest degradation. Quantum advantage persists even under realistic noise conditions.}
    \label{tab:noise_robustness}
    \begin{tabular}{lcccc}
        \toprule
        Configuration & Best & Mean $\pm$ Std & $n$ & vs Noiseless \\
        \midrule
        Noiseless ($L=1$, $α=0.05$) & 7\,300 & $7\,905 \pm 221$ & 30 & -- \\
        Noise ($L=1$, $α=0.05$) & 7\,350 & $7\,877 \pm 341$ & 10 & \textbf{-0.4\%} \\
        \midrule
        Noiseless ($L=2$, $α=0.05$) & 7\,290 & $7\,905 \pm 325$ & 30 & -- \\
        Noise ($L=2$, $α=0.05$) & 7\,780 & $8\,020 \pm 259$ & 10 & +1.5\% \\
        Noise ($L=2$, $α=1.0$) & 7\,810 & $8\,119 \pm 234$ & 10 & +2.7\% \\
        \bottomrule
    \end{tabular}
\end{table}

Noise impact analysis:
\begin{itemize}[nosep]
    \item \textbf{Shallow circuit resilience}: $L=1$ shows minimal degradation (-0.4\%) under realistic noise
    \item \textbf{Modest $L=2$ impact}: 1.5--2.7\% performance loss remains well below GA baseline ($8\,493$)
    \item \textbf{Preserved advantage}: Even noisy $L=2$ VQE significantly outperforms noiseless GA
\end{itemize}

Statistical significance testing (Mann-Whitney U, $p > 0.05$) confirms noise effects are not statistically significant, indicating robust real-world deployability.

\subsection{Statistical Validation}

% TODO: Add ANOVA results, confidence intervals, effect sizes
% Supporting the scientific rigor behind quantum advantage claims
% Bootstrap confidence intervals for mean differences
% Non-parametric statistical tests validating significance

\subsection{Summary}

Our systematic experimental evaluation demonstrates:
\begin{enumerate}[nosep]
    \item \textbf{Consistent quantum advantage}: 5--7\% improvement across optimization strategies
    \item \textbf{Parameter robustness}: Advantage persists across $(\alpha, L)$ hyperparameter space  
    \item \textbf{Budget efficiency}: Competitive performance achievable with reduced computational resources
    \item \textbf{Noise resilience}: Quantum advantage preserved under realistic hardware constraints
\end{enumerate}

These findings validate CVaR-VQE as a practical NISQ-era solution for constraint-heavy combinatorial optimization in drone logistics.

% TODO: Add discussion of limitations and failure modes
% TODO: Add comparison to other quantum optimization approaches
% TODO: Add computational resource requirements and wall-clock times
