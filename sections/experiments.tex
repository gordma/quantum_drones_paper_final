\section{Experimental Setup}
\label{sec:experiments}

\subsection{Problem Instance and Route Generation}

We construct a 30--40-node tactical delivery graph representing a realistic urban environment with battery constraints, payload limits, and regulatory no-fly zones.
Using the soft-max route generator described in Section~\ref{sec:problem}, we produce $N = 2\,048$ feasible candidate routes, each fully respecting:
\begin{itemize}[nosep]
    \item Battery capacity: $B_{max} = 80\,\text{Wh}$ with recharge rate $20\,\text{Wh/min}$
    \item Payload limit: $Q_{max} = 5\,\text{kg}$ per drone
    \item Wave scheduling: 4 discrete launch windows with inter-wave charging
    \item No-fly constraints: Embedded in graph adjacency
\end{itemize}

The combinatorial decision space contains ${2\,048 \choose 10} \times 4^{10} \approx 2.6 \times 10^{26}$ possibilities, encoded using $\lceil\log_2 2048\rceil + \lceil\log_2 4\rceil = 13$ qubits via index representation.

% \textit{Data source: Route generation uses parameters documented in experiments/ga\_parallel\_benchmark/ with softness=0.7 identified as optimal from 420-experiment parameter sweep.}

\subsection{Classical Baseline: Genetic Algorithm}

To ensure fair comparison, we establish a rigorously tuned GA baseline using comprehensive hyperparameter optimization.

\subsubsection{GA Configuration}
\begin{itemize}[nosep]
    \item \textbf{Encoding}: Bit-string representation ($\approx 130$ bits per chromosome)
    \item \textbf{Population}: Dynamic sizing based on chromosome length 
    \item \textbf{Selection}: Roulette wheel with elitism
    \item \textbf{Crossover}: Two-point crossover
    \item \textbf{Mutation}: Adaptive probability with extensive grid search
\end{itemize}

\subsubsection{Hyperparameter Optimization}
We conduct a systematic mutation probability sweep across $\mu \in \{0.15, 0.18, 0.20, 0.22, 0.25\}$ with 30 independent trials per configuration.
Statistical analysis identifies $\mu^* = 0.22$ as optimal, achieving mean cost $8\,493 \pm 420$ over 30 trials.

% \textit{Data source: GA optimization results stored in ga\_equal\_budget\_results.csv, generated by experiments/ga\_analysis/run\_ga\_equal\_budget.py with 2M evaluation budget per trial.}

\subsection{Quantum Pipeline: CVaR-VQE}

\subsubsection{Circuit Architecture}
We employ a hardware-efficient variational ansatz with $L \in \{1, 2\}$ layers, yielding 26--52 trainable parameters for the 13-qubit register.
Shallow circuits align with NISQ-era coherence limits while maintaining expressivity for the compressed encoding.

\subsubsection{Risk-Aware Objective}
Rather than optimizing the expectation $\mathbb{E}[C]$, we minimize the Conditional Value-at-Risk cost where the best $\alpha$-percentile of $N$ bitstrings drawn contributes to the objective function \cite{barkoutsos_improving_2020}:
\begin{equation}
    \text{CVaR}_\alpha[C] = \mathbb{E}[C \mid C \geq \text{VaR}_\alpha[C]]
\end{equation}


with $\alpha \in \{0.05, 0.1, 1.0\}$ focusing optimization on best-case tail costs.
This naturally handles heteroscedastic noise from (i) quantum shot sampling and (ii) Monte Carlo route subset evaluation.

\subsubsection{Bayesian Optimization}
We employ Optuna's Aggressive TPE sampler with hyperparameters:
\begin{itemize}
    \item \texttt{prior\_weight = 0.5} (aggressive exploration)
    \item \texttt{n\_ei\_candidates = 36} (broad search)  
    \item \texttt{MedianPruner} with 90\% retention
\end{itemize}

This configuration emerged from systematic comparison against Default-TPE and Random sampling across multiple trial budgets, see Appendix \ref{sec:appendix_parameters}.

% \textit{Data source: Bayesian optimization comparison documented in experiments/ga\_analysis/BAYESIAN\_OPTIMIZATION\_COMPARISON.md with performance analysis across conservative/default/aggressive TPE variants.}

\subsection{Evaluation Protocol}

\subsubsection{Budget Fairness}
All methods receive identical computational budgets of 200,000 objective function evaluations:
\begin{itemize}[nosep]
    \item \textbf{VQE (noiseless)}: 200 iterations $\times$ 1,000 samples (10,000 shots each)
    \item \textbf{VQE (noisy)}: 100 iterations $\times$ 1,000 samples (10,000 shots each)  
    \item \textbf{GA baseline}: 2,000 population size $\times$ 100 iterations
\end{itemize}
This represents a small fraction of the $O(10^{26})$ search space while ensuring fair comparison.

\subsubsection{Statistical Rigor}
Each configuration undergoes 30 independent trials with different random seeds to ensure statistical significance.
We report both best-case performance and mean $\pm$ standard deviation across trials.

% \textit{Data source: Main results from experiments/vqe\_final/ with 30 trials each for aggressive\_tpe/, default\_tpe/, and random/ optimizers.}

\subsection{Noise Modeling}

To validate practical deployability, we evaluate performance under realistic quantum noise using IBM's calibrated \texttt{ibm\_fez} noise model.
The study covers:
\begin{itemize}[nosep]
    \item \textbf{Circuit depths}: $L \in \{1, 2\}$ layers
    \item \textbf{Risk parameters}: $\alpha \in \{0.05, 0.1, 1.0\}$  
    \item \textbf{Optimizer comparison}: Aggressive-TPE vs Default-TPE vs Random
    \item \textbf{Statistical power}: 30 trials per configuration (ensuring robust statistical analysis)
\end{itemize}

Noiseless baselines use identical hyperparameters, enabling direct measurement of noise-induced performance degradation.

% \textit{Data source: Noise robustness studies in experiments/vqe\_noise\_L1\_a0.05/, experiments/vqe\_noise\_L2\_a0.05/, and experiments/vqe\_noise\_L2\_a1.0/ covering all optimizer$\times$noise combinations.}

% \subsection{Reproducibility}

% All experimental configurations, random seeds, and hyperparameters are documented in experiments/EXPERIMENT\_MASTER\_LOG.md.
% The complete codebase is released under MIT license with dependency specifications in requirements.txt.
% Figure generation scripts in figures/scripts/ ensure reproducible visualization of all results.

% TODO: Add experimental timeline and computational resources used
